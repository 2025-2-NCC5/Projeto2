# -*- coding: utf-8 -*-
"""projeto_trends_vendas_com_pytrends.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jVFVY8UUQnV6XsKcgvejCoSNn9CcLNDw

### Célula 1: Importar Bibliotecas

Esta célula prepara nosso ambiente. Importamos as bibliotecas para análise de dados (Pandas, Numpy), visualização (Matplotlib, Seaborn) e os modelos de Machine Learning (LinearRegression, RandomForestRegressor) e métricas (r2_score).
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import r2_score, mean_squared_error

!pip install pytrends pandas

"""### Célula 2: Carregar Dados Internos (Pedidos)

Carregamos o `pedidos_categorizados.csv` (nossas vendas reais) e garantimos que a coluna de data esteja no formato correto.
"""

try:
    df_pedidos =pd.read_csv('https://raw.githubusercontent.com/2025-2-NCC5/Projeto2/main/cannoli_atualizado.csv')
    df_pedidos['Data_Pedido'] = pd.to_datetime(df_pedidos['Data_Pedido'], dayfirst=True, format='mixed')

    print("Dados de pedidos carregados com sucesso:")
    print(df_pedidos.head())
except FileNotFoundError:
    print("Erro: Arquivo 'cannoli_atualizado.csv' não encontrado.")
    print("Por favor, faça o upload do arquivo para o ambiente do Colab.")

"""### Célula 3: Processar Dados Internos (Agregar por Dia)

Não podemos comparar tendências diárias com pedidos individuais. Precisamos saber o **total** de vendas de cada categoria *por dia*. Vamos agrupar (groupby) e depois "pivotar" (pivot) a tabela.
"""

# Contar quantos pedidos de cada categoria tivemos por dia
df_agg = df_pedidos.groupby(['Data_Pedido', 'Categoria_Comida']).size().reset_index(name='Total_Pedidos')

# Pivotar a tabela para o formato: Data | Pizza | Hambúrguer | Sushi
df_vendas_diarias = df_agg.pivot(index='Data_Pedido', columns='Categoria_Comida', values='Total_Pedidos').fillna(0)

# Resetar o índice para a data voltar a ser uma coluna
df_vendas_diarias = df_vendas_diarias.reset_index()

# Garantir que a data esteja sem fuso horário para o merge
df_vendas_diarias['Data_Pedido'] = pd.to_datetime(df_vendas_diarias['Data_Pedido']).dt.tz_localize(None)

print("Dados de vendas agregados por dia:")
print(df_vendas_diarias.head())

"""### Célula 4: Instalar e Importar Pytrends

Esta é a primeira parte do seu código. Instalamos a biblioteca `pytrends`.

### Célula 5: Carregar Dados Externos (Google Trends)

Esta é a segunda parte do seu código. Vamos conectar e buscar os dados reais do Google Trends para os últimos 3 meses.
"""

pytrends = TrendReq(hl='pt-BR', tz=360)

keywords = ["pizza", "hambúrguer", "sushi"]

pytrends.build_payload(keywords, cat=0, timeframe='today 3-m', geo='BR', gprop='')

df_trends_raw = pytrends.interest_over_time()

print("✅ Tendências de comidas (Google Trends - últimos 3 meses):")
display(df_trends_raw.head())

"""### Célula 6: Processar e Alinhar Dados do Google Trends

Os dados do Pytrends precisam ser "limpos" antes de podermos usá-los:
1.  Resetamos o índice (`date`) para que ele se torne uma coluna.
2.  Convertemos essa coluna de data para `datetime` e removemos o fuso horário (`tz_localize(None)`) para que ela possa ser unida com nossos dados de vendas.
3.  Renomeamos as colunas (ex: `pizza` para `pizza_trend`) para o nosso modelo.
4.  Removemos colunas que não usaremos (como `isPartial`, `nike`).
"""

df_trends = df_trends_raw.reset_index()

df_trends = df_trends.rename(columns={
    'date': 'Data_Pedido',
    'pizza': 'pizza_trend',
    'hambúrguer': 'hamburguer_trend',
    'sushi': 'sushi_trend'
})

df_trends['Data_Pedido'] = pd.to_datetime(df_trends['Data_Pedido']).dt.tz_localize(None)

colunas_para_manter = ['Data_Pedido', 'pizza_trend', 'hamburguer_trend', 'sushi_trend']
df_trends = df_trends[colunas_para_manter]

print("Dados do Google Trends processados e prontos para unir:")
print(df_trends.head())

"""### Célula 7: Unir Fontes de Dados

Agora, unimos nossas Vendas Diárias (`df_vendas_diarias`) com os dados reais do Google Trends (`df_trends`) usando a data.
"""

df_modelo = pd.merge(df_vendas_diarias, df_trends, on='Data_Pedido', how='inner')

print("Dados combinados para modelagem (Vendas + Trends):")
print(df_modelo.head())

"""### Célula 8: Análise Exploratória (EDA) - Função `freq`

Esta é a sua função `freq` original. Vamos usá-la para analisar a distribuição das nossas categorias de comida nos dados de pedidos.
"""

def freq(x: pd.Series, plot=False):
    contagem = x.value_counts(dropna=False)
    percentual = round((contagem / x.shape[0]) * 100, 3)

    res = pd.DataFrame({'n': contagem, 'perc': percentual})
    res.index.name = 'values'

    if plot:
        sns.countplot(x=x)
        plt.show()

    return res

"""### Célula 9: EDA - Frequência de Categorias

Analisando o dataset de pedidos original para ver quais categorias são mais vendidas.
"""

print("Frequência de Pedidos por Categoria (dataset original):")
display(freq(df_pedidos['Categoria_Comida'], plot=True))

"""### Célula 10: EDA - Resumo Estatístico

Adaptamos esta célula (que antes olhava o `taxid`) para olhar as colunas que vamos usar no modelo: `Pizza` (vendas) e `pizza_trend` (buscas).
"""

print("Resumo estatístico das vendas de Pizza (por dia):")
print(df_modelo['Pizza'].describe())
print("\nResumo estatístico das buscas por Pizza (Trend):")
print(df_modelo['pizza_trend'].describe())

"""### Célula 11: EDA - Boxplot

Vamos usar o boxplot para ver a distribuição das nossas duas variáveis principais (vendas e buscas).
"""

plt.figure(figsize=(10, 4))
plt.subplot(1, 2, 1)
sns.boxplot(y=df_modelo['Pizza'])
plt.title('Distribuição de Vendas de Pizza')

plt.subplot(1, 2, 2)
sns.boxplot(y=df_modelo['pizza_trend'])
plt.title('Distribuição de Buscas (Trend)')
plt.show()

"""### Célula 12: Definir X e y (O Foco do Projeto)

Definimos o que queremos prever e o que vamos usar para prever.
* **`y` (alvo):** `Pizza` (o número de pedidos).
* **`X` (features):** `pizza_trend` (o dado do Google).
"""

y = df_modelo['Pizza']

X = df_modelo[['pizza_trend']]

print(f"Formato de X: {X.shape}")
print(f"Formato de y: {y.shape}")

"""### Célula 13: Dividir Dados em Treino e Teste

Dividimos os dados para treinar e testar os modelos de forma justa.
"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

"""### Célula 14: Modelo 1 (Baseline) - Regressão Linear

Treinamos o primeiro modelo. A Regressão Linear é a melhor ferramenta para medir a **correlação** e responder à sua pergunta de negócio.
"""

model_lr = LinearRegression()
model_lr.fit(X_train, y_train)

print("Modelo 1 (Regressão Linear) treinado com sucesso!")

"""### Célula 15: Avaliação e Interpretação (Regressão Linear)

Avaliamos o modelo com **R²** (R-squared) e extraímos o **coeficiente**.
* **R²:** Quão bem as buscas explicam as vendas (0 a 1). Um R² negativo ou próximo de 0 significa que NÃO HÁ correlação linear.
* **Coeficiente:** O "insight" principal (quantos pedidos a mais por ponto de busca).
"""

y_pred_lr = model_lr.predict(X_test)
r2_lr = r2_score(y_test, y_pred_lr)
coef_lr = model_lr.coef_[0]

print(f"--- Avaliação (Regressão Linear) ---")
print(f"Score R²: {r2_lr:.4f}")

print(f"--- Interpretação (Insight do Negócio) ---")
print(f"Coeficiente: {coef_lr:.4f}")
print(f"Para cada 1 ponto de aumento no 'pizza_trend' do Google,")
print(f"o modelo prevê uma mudança de {coef_lr:.4f} nos pedidos de pizza.")

"""### Célula 16: Visualização (Regressão Linear)

Plotamos os dados reais (pontos) contra a linha de correlação (vermelha) que o modelo encontrou. Se a linha estiver subindo e os pontos próximos a ela, há uma correlação positiva.
"""

plt.figure(figsize=(10, 6))
sns.scatterplot(x=X_test['pizza_trend'], y=y_test, label='Dados Reais (Teste)', s=100, alpha=0.7)
sns.lineplot(x=X_test['pizza_trend'], y=y_pred_lr, color='red', label='Linha de Previsão (Regressão Linear)')
plt.title('Correlação: Busca (Google) vs. Pedidos de Pizza (Reais)')
plt.xlabel('Nível de Busca (Google Trend)')
plt.ylabel('Total de Pedidos de Pizza')
plt.legend()
plt.show()

"""### Célula 17: Modelo 2 (Avançado) - Random Forest Regressor
O `RandomForestRegressor` é mais potente e pode encontrar padrões não-lineares (relações mais complexas).
"""

model_rf = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=5)
model_rf.fit(X_train, y_train)

print("Modelo 2 (Random Forest Regressor) treinado com sucesso!")

"""### Célula 18: Avaliação (Random Forest Regressor)

Avaliamos o modelo Random Forest. Como ele é mais complexo, podemos comparar seu R² com o do modelo linear.
"""

y_pred_rf = model_rf.predict(X_test)
r2_rf = r2_score(y_test, y_pred_rf)

print(f"--- Avaliação (Random Forest) ---")
print(f"Score R²: {r2_rf:.4f}")

print(f"\nComparação R²:")
print(f"Linear Regression: {r2_lr:.4f}")
print(f"Random Forest:     {r2_rf:.4f}")

"""### Célula 19: Visualização (Random Forest)

Para um modelo não-linear, o melhor gráfico é "Valores Reais vs. Valores Previstos". Se os pontos formarem uma linha reta diagonal perfeita, o modelo é perfeito.
"""

plt.figure(figsize=(8, 8))
sns.scatterplot(x=y_test, y=y_pred_rf, s=100, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', label='Previsão Perfeita')
plt.title('Random Forest: Valores Reais vs. Valores Previstos')
plt.xlabel('Valores Reais - Pedidos pizza')
plt.ylabel('Valores Previstos - Nota Google Trends')
plt.legend()
plt.show()